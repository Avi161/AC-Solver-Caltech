{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AC-Solver Iterative Refinement \u2014 Colab Runner\n",
    "\n",
    "**Runtime recommendation: High-RAM CPU**  \n",
    "The search (V-guided greedy, beam) is CPU-only. GPU only helps training, which takes ~10 min per iteration \u2014 not the bottleneck.\n",
    "\n",
    "**Normal workflow:**\n",
    "- **First time / clean restart:** Cells 1 \u2192 2 \u2192 3 \u2192 4 \u2192 5 \u2192 6\n",
    "- **After Colab disconnect:** Cells 1 \u2192 2 \u2192 3 \u2192 5 \u2192 8 *(state persists on Drive)*\n",
    "- **If state files are missing but partial results exist:** Cells 1 \u2192 2 \u2192 3 \u2192 5 \u2192 7 \u2192 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1 \u2014 Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "Drive mounted.\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "print('Drive mounted.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2 \u2014 Clone or Update Repo on Drive\n",
    "\n",
    "**First time only:** enter your GitHub Personal Access Token when prompted.  \n",
    "Get one at: GitHub \u2192 Settings \u2192 Developer Settings \u2192 Personal access tokens \u2192 Fine-grained \u2192 repo read access.  \n",
    "After first clone, this cell just does `git pull`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n",
      "\n",
      "Working directory: /content/drive/MyDrive/AC-Solver-Caltech\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "REPO_URL = 'https://github.com/Avi161/AC-Solver-Caltech.git'\n",
    "DRIVE_DIR = '/content/drive/MyDrive/AC-Solver-Caltech'\n",
    "BRANCH = 'feat/test-new-exp-claude'\n",
    "\n",
    "if not os.path.exists(DRIVE_DIR):\n",
    "    # First time: clone with token\n",
    "    from getpass import getpass\n",
    "    token = getpass('GitHub Personal Access Token: ')\n",
    "    auth_url = REPO_URL.replace('https://', f'https://{token}@')\n",
    "    subprocess.run(['git', 'clone', auth_url, DRIVE_DIR], check=True)\n",
    "    subprocess.run(['git', 'checkout', BRANCH], cwd=DRIVE_DIR, check=True)\n",
    "    print('Repo cloned to Drive.')\n",
    "else:\n",
    "    # Already cloned: checkout branch first, then pull\n",
    "    subprocess.run(['git', 'checkout', BRANCH], cwd=DRIVE_DIR, check=True)\n",
    "    result = subprocess.run(['git', 'pull'], cwd=DRIVE_DIR, capture_output=True, text=True)\n",
    "    print(result.stdout or 'Already up to date.')\n",
    "\n",
    "os.chdir(DRIVE_DIR)\n",
    "print(f'Working directory: {os.getcwd()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3 \u2014 Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "result = subprocess.run(\n",
    "    ['pip', 'install', '-q', '-r', 'requirements.txt'],\n",
    "    cwd=DRIVE_DIR, capture_output=True, text=True\n",
    ")\n",
    "print(result.stdout[-2000:] if result.stdout else 'Done.')\n",
    "if result.returncode != 0:\n",
    "    print('ERRORS:', result.stderr[-1000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4 \u2014 Verify Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \u2713  Original model checkpoint\n",
      "  \u2713  Feature stats\n",
      "  \u2713  Greedy solved presentations\n",
      "  \u2713  Greedy search paths\n",
      "  \u2713  Config\n",
      "\n",
      "  No saved state \u2014 will start fresh.\n",
      "\n",
      "All checks passed. Ready to run.\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "\n",
    "checks = {\n",
    "    'Original model checkpoint':  'value_search/checkpoints/best_mlp.pt',\n",
    "    'Feature stats':              'value_search/checkpoints/feature_stats.json',\n",
    "    'Greedy solved presentations': 'ac_solver/search/miller_schupp/data/greedy_solved_presentations.txt',\n",
    "    'Greedy search paths':         'ac_solver/search/miller_schupp/data/greedy_search_paths.txt',\n",
    "    'Config':                      'experiments/config.yaml',\n",
    "}\n",
    "\n",
    "all_ok = True\n",
    "for label, path in checks.items():\n",
    "    full = os.path.join(DRIVE_DIR, path)\n",
    "    exists = os.path.exists(full)\n",
    "    status = '\u2713' if exists else '\u2717  MISSING'\n",
    "    print(f'  {status}  {label}')\n",
    "    if not exists:\n",
    "        all_ok = False\n",
    "\n",
    "# Check refinement state (if resuming)\n",
    "state_file = os.path.join(DRIVE_DIR, 'experiments/refinement/refinement_state.json')\n",
    "if os.path.exists(state_file):\n",
    "    with open(state_file) as f:\n",
    "        state = json.load(f)\n",
    "    print(f'\\n  Saved state found: iteration={state[\"iteration\"]}, '\n",
    "          f'total_solved_history={state[\"total_solved_per_iteration\"]}')\n",
    "else:\n",
    "    print('\\n  No saved state \u2014 will start fresh.')\n",
    "\n",
    "if all_ok:\n",
    "    print('\\nAll checks passed. Ready to run.')\n",
    "else:\n",
    "    print('\\nFix missing files before running.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5 \u2014 Configuration\n",
    "Edit these before running. Then run Cell 6 (fresh start) or Cell 8 (resume)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config set:\n",
      "  max_iterations  = 5\n",
      "  max_path_length = 300\n",
      "  enable_mcts     = False\n",
      "  max_nodes       = 100,000\n"
     ]
    }
   ],
   "source": [
    "# \u2500\u2500 Tune these \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nMAX_ITERATIONS  = 5       # How many search\u2192train cycles\nMAX_PATH_LENGTH = 300     # Reject training paths longer than this\nENABLE_MCTS     = False   # MCTS is slow; keep False unless you have many hours\nMAX_NODES       = 100_000 # 100K nodes: ~25s per presentation, ~5hrs per iteration\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nimport sys\nsys.path.insert(0, DRIVE_DIR)\n\nprint('Config set:')\nprint(f'  max_iterations  = {MAX_ITERATIONS}')\nprint(f'  max_path_length = {MAX_PATH_LENGTH}')\nprint(f'  enable_mcts     = {ENABLE_MCTS}')\nprint(f'  max_nodes       = {MAX_NODES:,}')\n\n\n# \u2500\u2500 Progress streaming helper (used by Cells 6 and 7) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ndef run_with_progress(cmd, cwd):\n    \"\"\"Run cmd as subprocess, printing headers normally and progress on one line.\"\"\"\n    import subprocess, sys, os\n\n    HEADER_PATTERNS = [\n        '===', 'ITERATION', '--- Step', 'complete:', 'REFINEMENT COMPLETE',\n        'ERROR', 'Traceback', 'File \"', 'Error:', 'Running:', 'Resuming:',\n        'Total presentations', 'Greedy baseline', 'Resumed from',\n        'No previous state', 'Loading greedy', 'Converged', 'Interrupted',\n        'State saved', '[idx=',\n    ]\n\n    env = os.environ.copy()\n    env['PYTHONUNBUFFERED'] = '1'  # force line-by-line flushing in subprocess\n\n    proc = subprocess.Popen(\n        cmd, cwd=cwd,\n        stdout=subprocess.PIPE, stderr=subprocess.STDOUT,\n        text=True, bufsize=1, env=env,\n    )\n\n    last_was_progress = False\n    for raw in proc.stdout:\n        line = raw.rstrip()\n        if not line:\n            continue\n        is_header = any(p in line for p in HEADER_PATTERNS)\n        if is_header:\n            if last_was_progress:\n                sys.stdout.write('\\n')\n            print(line)\n            last_was_progress = False\n        else:\n            sys.stdout.write(f'\\r  {line:<90}')\n            sys.stdout.flush()\n            last_was_progress = True\n\n    if last_was_progress:\n        sys.stdout.write('\\n')\n    proc.wait()\n    return proc.returncode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6 \u2014 Fresh Start\n",
    "Run this to begin a new refinement run from the greedy baseline. **Skip if resuming an existing run.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running: /usr/bin/python3 /content/drive/MyDrive/AC-Solver-Caltech/experiments/iterative_refinement.py --max-iterations 5 --max-path-length 300 --max-nodes 100000\n",
      "======================================================================\n",
      "    AC-Solver Iterative Refinement Pipeline                                                 \n",
      "======================================================================\n",
      "    State file:     /content/drive/MyDrive/AC-Solver-Caltech/experiments/refinement/refinement_state.json\n",
      "======================================================================\n",
      "  Total presentations: 1190\n",
      "  Loading greedy-solved paths as seed...\n",
      "  Greedy baseline: 533 solved\n",
      "======================================================================\n",
      "  ITERATION 0\n",
      "======================================================================\n",
      "    Model: /content/drive/MyDrive/AC-Solver-Caltech/value_search/checkpoints/best_mlp.pt (original, trained on greedy paths)\n",
      "  --- Step 1: Search ---\n",
      "    Searching 657/1190 unsolved presentations                                               \n",
      "  Running: /usr/bin/python3 /content/drive/MyDrive/AC-Solver-Caltech/experiments/run_experiments.py --config /content/drive/MyDrive/AC-Solver-Caltech/experiments/refinement/iter_0/iter_config.yaml --indices /content/drive/MyDrive/AC-Solver-Caltech/experiments/refinement/iter_0/unsolved_indices.txt\n",
      "============================================================\n",
      "    AC-Solver Experiment Runner                                                             \n",
      "============================================================\n",
      "    Started:    2026-02-26_04-06-25                                                         6-25ig.yaml\n",
      "============================================================\n",
      "  Loading presentations...                                                                  \n",
      "  Total presentations: 1190\n",
      "    --indices: running on 657/1190 presentations                                            \n",
      "============================================================\n",
      "    [3] V-GUIDED GREEDY (ours, mlp + cyclic reduce) \u2014 100,000 nodes                         \n",
      "============================================================\n",
      "      V-Greedy: 200/657, solved=5, ETA 11.2h                                                "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'https://8080-m-hm-l0clbxvw5hnh-c.europe-west4-1.prod.colab.dev/'. Verify the server is running and reachable."
     ]
    }
   ],
   "source": [
    "cmd = [\n",
    "    sys.executable,\n",
    "    os.path.join(DRIVE_DIR, 'experiments/iterative_refinement.py'),\n",
    "    '--max-iterations', str(MAX_ITERATIONS),\n",
    "    '--max-path-length', str(MAX_PATH_LENGTH),\n",
    "]\n",
    "if ENABLE_MCTS:\n",
    "    cmd.append('--enable-mcts')\n",
    "if MAX_NODES is not None:\n",
    "    cmd.extend(['--max-nodes', str(MAX_NODES)])\n",
    "\n",
    "print('Running:', ' '.join(cmd))\n",
    "rc = run_with_progress(cmd, cwd=DRIVE_DIR)\n",
    "print('Exit code:', rc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7 \u2014 Reconstruct State (run only if state files are missing)\n",
    "Run this **only** when `refinement_state.json` is missing but partial search results exist on Drive (e.g. after accidentally deleting state or after a very early crash before any state was saved).  \n",
    "It auto-detects the latest partial results directory and rebuilds both state files.  \n",
    "Then run Cell 8 to continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using partial results dir: /content/drive/MyDrive/AC-Solver-Caltech/experiments/results/2026-02-26_04-06-25\n",
      "  Contains: 397 processed, 6 solved: [599, 689, 698, 711, 712, 834]\n",
      "Greedy paths loaded: 533\n",
      "Written: all_solved_paths.json (533 paths)\n",
      "Written: refinement_state.json\n",
      "\n",
      "Ready \u2014 run Cell 8 (Resume).\n"
     ]
    }
   ],
   "source": [
    "import os, sys, json\n",
    "\n",
    "sys.path.insert(0, DRIVE_DIR)\n",
    "from value_search.data_extraction import load_presentations, load_paths\n",
    "\n",
    "DATA_DIR       = os.path.join(DRIVE_DIR, 'ac_solver/search/miller_schupp/data')\n",
    "REFINEMENT_DIR = os.path.join(DRIVE_DIR, 'experiments/refinement')\n",
    "RESULTS_BASE   = os.path.join(DRIVE_DIR, 'experiments/results')\n",
    "os.makedirs(REFINEMENT_DIR, exist_ok=True)\n",
    "\n",
    "# 1. Auto-detect the latest partial results directory\n",
    "candidate_dirs = sorted([\n",
    "    d for d in os.listdir(RESULTS_BASE)\n",
    "    if os.path.isdir(os.path.join(RESULTS_BASE, d))\n",
    "    and os.path.exists(os.path.join(RESULTS_BASE, d, 'v_guided_greedy_progress.jsonl'))\n",
    "])\n",
    "if not candidate_dirs:\n",
    "    print(\"ERROR: No partial results found in\", RESULTS_BASE)\n",
    "    raise SystemExit\n",
    "\n",
    "PARTIAL_DIR = os.path.join(RESULTS_BASE, candidate_dirs[-1])\n",
    "print(f\"Using partial results dir: {PARTIAL_DIR}\")\n",
    "\n",
    "# Show what's in it\n",
    "jsonl = os.path.join(PARTIAL_DIR, 'v_guided_greedy_progress.jsonl')\n",
    "total, solved_indices = 0, []\n",
    "with open(jsonl) as f:\n",
    "    for line in f:\n",
    "        r = json.loads(line)\n",
    "        total += 1\n",
    "        if r.get('solved'):\n",
    "            solved_indices.append(r['idx'])\n",
    "print(f\"  Contains: {total} processed, {len(solved_indices)} solved: {solved_indices}\")\n",
    "\n",
    "# 2. Reload greedy paths from source data\n",
    "solved_pres = load_presentations(os.path.join(DATA_DIR, 'greedy_solved_presentations.txt'))\n",
    "raw_paths   = load_paths(os.path.join(DATA_DIR, 'greedy_search_paths.txt'))\n",
    "greedy_paths = {\n",
    "    tuple(pres): [[a - 1, l] for a, l in raw_path[1:]]\n",
    "    for pres, raw_path in zip(solved_pres, raw_paths)\n",
    "}\n",
    "print(f\"Greedy paths loaded: {len(greedy_paths)}\")\n",
    "\n",
    "# 3. Write all_solved_paths.json\n",
    "paths_file = os.path.join(REFINEMENT_DIR, 'all_solved_paths.json')\n",
    "with open(paths_file, 'w') as f:\n",
    "    json.dump({str(list(k)): v for k, v in greedy_paths.items()}, f)\n",
    "print(f\"Written: all_solved_paths.json ({len(greedy_paths)} paths)\")\n",
    "\n",
    "# 4. Write refinement_state.json pointing at partial results\n",
    "state = {\n",
    "    \"iteration\": 0,\n",
    "    \"solved_per_iteration\": [],\n",
    "    \"total_solved_per_iteration\": [len(greedy_paths)],\n",
    "    \"model_paths\": [],\n",
    "    \"results_dirs\": [PARTIAL_DIR],\n",
    "}\n",
    "state_file = os.path.join(REFINEMENT_DIR, 'refinement_state.json')\n",
    "with open(state_file, 'w') as f:\n",
    "    json.dump(state, f, indent=2)\n",
    "print(f\"Written: refinement_state.json\")\n",
    "print(f\"\\nReady \u2014 run Cell 8 (Resume).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8 \u2014 Resume After Disconnect\n",
    "After Colab disconnects: re-run Cells 1 \u2192 2 \u2192 3 \u2192 5, then run this cell.  \n",
    "Picks up from the last completed iteration automatically \u2014 state persists on Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming: /usr/bin/python3 /content/drive/MyDrive/AC-Solver-Caltech/experiments/iterative_refinement.py --resume --max-iterations 5 --max-path-length 300 --max-nodes 100000\n",
      "======================================================================\n",
      "    AC-Solver Iterative Refinement Pipeline                                                 \n",
      "======================================================================\n",
      "    State file:     /content/drive/MyDrive/AC-Solver-Caltech/experiments/refinement/refinement_state.json\n",
      "======================================================================\n",
      "  Total presentations: 1190\n",
      "  Resumed from iteration 0\n",
      "    Previously solved: 533/1190                                                             \n",
      "======================================================================\n",
      "  ITERATION 0\n",
      "======================================================================\n",
      "    Model: /content/drive/MyDrive/AC-Solver-Caltech/value_search/checkpoints/best_mlp.pt (original, trained on greedy paths)\n",
      "  --- Step 1: Search ---\n",
      "    Resuming search from: /content/drive/MyDrive/AC-Solver-Caltech/experiments/results/2026-02-26_04-06-25\n",
      "  Running: /usr/bin/python3 /content/drive/MyDrive/AC-Solver-Caltech/experiments/run_experiments.py --config /content/drive/MyDrive/AC-Solver-Caltech/experiments/refinement/iter_0/iter_config.yaml --indices /content/drive/MyDrive/AC-Solver-Caltech/experiments/refinement/iter_0/unsolved_indices.txt --resume-dir /content/drive/MyDrive/AC-Solver-Caltech/experiments/results/2026-02-26_04-06-25\n",
      "============================================================\n",
      "    AC-Solver Experiment Runner                                                             \n",
      "============================================================\n",
      "    Started:    2026-02-26_04-06-25                                                         6-25ig.yaml\n",
      "============================================================\n",
      "  Loading presentations...                                                                  \n",
      "  Total presentations: 1190\n",
      "    --indices: running on 657/1190 presentations                                            \n",
      "============================================================\n",
      "    [3] V-GUIDED GREEDY (ours, mlp + cyclic reduce) \u2014 100,000 nodes                         \n",
      "============================================================\n",
      "  Resuming: skipping 398 already processed\n"
     ]
    }
   ],
   "source": [
    "cmd = [\n",
    "    sys.executable,\n",
    "    os.path.join(DRIVE_DIR, 'experiments/iterative_refinement.py'),\n",
    "    '--resume',\n",
    "    '--max-iterations', str(MAX_ITERATIONS),\n",
    "    '--max-path-length', str(MAX_PATH_LENGTH),\n",
    "]\n",
    "if ENABLE_MCTS:\n",
    "    cmd.append('--enable-mcts')\n",
    "if MAX_NODES is not None:\n",
    "    cmd.extend(['--max-nodes', str(MAX_NODES)])\n",
    "\n",
    "print('Resuming:', ' '.join(cmd))\n",
    "rc = run_with_progress(cmd, cwd=DRIVE_DIR)\n",
    "print('Exit code:', rc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 9 \u2014 Check Progress Anytime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "\n",
    "state_file = os.path.join(DRIVE_DIR, 'experiments/refinement/refinement_state.json')\n",
    "if not os.path.exists(state_file):\n",
    "    print('No state file \u2014 run Cell 6 (fresh start) or Cell 7 (reconstruct state) first.')\n",
    "else:\n",
    "    with open(state_file) as f:\n",
    "        state = json.load(f)\n",
    "\n",
    "    paths_file = os.path.join(DRIVE_DIR, 'experiments/refinement/all_solved_paths.json')\n",
    "    total_solved = 0\n",
    "    if os.path.exists(paths_file):\n",
    "        with open(paths_file) as f:\n",
    "            total_solved = len(json.load(f))\n",
    "\n",
    "    print(f'Current iteration:  {state[\"iteration\"]}')\n",
    "    print(f'Total solved:       {total_solved}/1190')\n",
    "    print(f'Solved per iter:    {state[\"solved_per_iteration\"]}')\n",
    "    print(f'Total per iter:     {state[\"total_solved_per_iteration\"]}')\n",
    "\n",
    "    refinement_dir = os.path.join(DRIVE_DIR, 'experiments/refinement')\n",
    "    print(f'\\nFiles in refinement dir:')\n",
    "    for f in sorted(os.listdir(refinement_dir)):\n",
    "        fpath = os.path.join(refinement_dir, f)\n",
    "        size_mb = os.path.getsize(fpath) / 1e6 if os.path.isfile(fpath) else 0\n",
    "        tag = f'({size_mb:.1f} MB)' if os.path.isfile(fpath) else '(dir)'\n",
    "        print(f'  {f}  {tag}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
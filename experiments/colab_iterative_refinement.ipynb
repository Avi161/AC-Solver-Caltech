{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AC-Solver Iterative Refinement — Colab Runner\n",
    "\n",
    "**Runtime recommendation: High-RAM CPU**  \n",
    "The search (V-guided greedy, beam) is CPU-only. GPU only helps training, which takes ~10 min per iteration — not the bottleneck.\n",
    "\n",
    "**Normal workflow:**\n",
    "- **First time / clean restart:** Cells 1 → 2 → 3 → 4 → 5 → 6\n",
    "- **After Colab disconnect:** Cells 1 → 2 → 3 → 5 → 8 *(state persists on Drive)*\n",
    "- **If state files are missing but partial results exist:** Cells 1 → 2 → 3 → 5 → 7 → 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1 — Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "Drive mounted.\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "print('Drive mounted.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2 — Clone or Update Repo on Drive\n",
    "\n",
    "**First time only:** enter your GitHub Personal Access Token when prompted.  \n",
    "Get one at: GitHub → Settings → Developer Settings → Personal access tokens → Fine-grained → repo read access.  \n",
    "After first clone, this cell just does `git pull`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating d7d1132..133042e\n",
      "Fast-forward\n",
      " experiments/colab_iterative_refinement.ipynb | 239 +++++++++++++++++++--------\n",
      " experiments/run_experiments.py               |  12 +-\n",
      " 2 files changed, 179 insertions(+), 72 deletions(-)\n",
      "\n",
      "Working directory: /content/drive/MyDrive/AC-Solver-Caltech\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "REPO_URL = 'https://github.com/Avi161/AC-Solver-Caltech.git'\n",
    "DRIVE_DIR = '/content/drive/MyDrive/AC-Solver-Caltech'\n",
    "BRANCH = 'feat/test-new-exp-claude'\n",
    "\n",
    "if not os.path.exists(DRIVE_DIR):\n",
    "    # First time: clone with token\n",
    "    from getpass import getpass\n",
    "    token = getpass('GitHub Personal Access Token: ')\n",
    "    auth_url = REPO_URL.replace('https://', f'https://{token}@')\n",
    "    subprocess.run(['git', 'clone', auth_url, DRIVE_DIR], check=True)\n",
    "    subprocess.run(['git', 'checkout', BRANCH], cwd=DRIVE_DIR, check=True)\n",
    "    print('Repo cloned to Drive.')\n",
    "else:\n",
    "    # Already cloned: checkout branch first, then pull\n",
    "    subprocess.run(['git', 'checkout', BRANCH], cwd=DRIVE_DIR, check=True)\n",
    "    result = subprocess.run(['git', 'pull'], cwd=DRIVE_DIR, capture_output=True, text=True)\n",
    "    print(result.stdout or 'Already up to date.')\n",
    "\n",
    "os.chdir(DRIVE_DIR)\n",
    "print(f'Working directory: {os.getcwd()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3 — Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "result = subprocess.run(\n",
    "    ['pip', 'install', '-q', '-r', 'requirements.txt'],\n",
    "    cwd=DRIVE_DIR, capture_output=True, text=True\n",
    ")\n",
    "print(result.stdout[-2000:] if result.stdout else 'Done.')\n",
    "if result.returncode != 0:\n",
    "    print('ERRORS:', result.stderr[-1000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4 — Verify Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓  Original model checkpoint\n",
      "  ✓  Feature stats\n",
      "  ✓  Greedy solved presentations\n",
      "  ✓  Greedy search paths\n",
      "  ✓  Config\n",
      "\n",
      "  Saved state found: iteration=0, total_solved_history=[533]\n",
      "\n",
      "All checks passed. Ready to run.\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "\n",
    "checks = {\n",
    "    'Original model checkpoint':  'value_search/checkpoints/best_mlp.pt',\n",
    "    'Feature stats':              'value_search/checkpoints/feature_stats.json',\n",
    "    'Greedy solved presentations': 'ac_solver/search/miller_schupp/data/greedy_solved_presentations.txt',\n",
    "    'Greedy search paths':         'ac_solver/search/miller_schupp/data/greedy_search_paths.txt',\n",
    "    'Config':                      'experiments/config.yaml',\n",
    "}\n",
    "\n",
    "all_ok = True\n",
    "for label, path in checks.items():\n",
    "    full = os.path.join(DRIVE_DIR, path)\n",
    "    exists = os.path.exists(full)\n",
    "    status = '✓' if exists else '✗  MISSING'\n",
    "    print(f'  {status}  {label}')\n",
    "    if not exists:\n",
    "        all_ok = False\n",
    "\n",
    "# Check refinement state (if resuming)\n",
    "state_file = os.path.join(DRIVE_DIR, 'experiments/refinement/refinement_state.json')\n",
    "if os.path.exists(state_file):\n",
    "    with open(state_file) as f:\n",
    "        state = json.load(f)\n",
    "    print(f'\\n  Saved state found: iteration={state[\"iteration\"]}, '\n",
    "          f'total_solved_history={state[\"total_solved_per_iteration\"]}')\n",
    "else:\n",
    "    print('\\n  No saved state — will start fresh.')\n",
    "\n",
    "if all_ok:\n",
    "    print('\\nAll checks passed. Ready to run.')\n",
    "else:\n",
    "    print('\\nFix missing files before running.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5 — Configuration\n",
    "Edit these before running. Then run Cell 6 (fresh start) or Cell 8 (resume)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── Tune these ────────────────────────────────────────────────────────────────\nMAX_ITERATIONS      = 5       # How many search→train cycles\nMAX_PATH_LENGTH     = 800     # Reject training paths longer than this\nMAX_NODES           = 100_000 # 100K nodes: ~25s per presentation, ~5hrs per iteration\nTIME_LIMIT_PER_PRES = 90      # Seconds per presentation for search (45–90)\n\n# ── Architecture / algorithm toggles ──────────────────────────────────────────\nRUN_MLP     = False  # Include MLP (v-guided greedy with MLP model)\nRUN_SEQ     = True   # Include Seq (v-guided greedy with seq model)\nENABLE_MCTS = False  # MCTS search  (very slow; keep False unless you have many hours)\nENABLE_BEAM = False  # Beam search  (k=10; finds solutions but paths are very long)\n# ──────────────────────────────────────────────────────────────────────────────\n\nimport sys\nsys.path.insert(0, DRIVE_DIR)\n\nprint('Config set:')\nprint(f'  max_iterations      = {MAX_ITERATIONS}')\nprint(f'  max_path_length     = {MAX_PATH_LENGTH}')\nprint(f'  max_nodes           = {MAX_NODES:,}')\nprint(f'  time_limit_per_pres = {TIME_LIMIT_PER_PRES}s')\nprint(f'  run_mlp             = {RUN_MLP}')\nprint(f'  run_seq             = {RUN_SEQ}')\nprint(f'  enable_mcts         = {ENABLE_MCTS}')\nprint(f'  enable_beam         = {ENABLE_BEAM}')\n\n\n# ── Progress streaming helper (used by Cells 6 and 8) ─────────────────────────\ndef run_with_progress(cmd, cwd):\n    \"\"\"Run cmd as subprocess, printing headers normally and progress on one line.\"\"\"\n    import subprocess, sys, os\n\n    HEADER_PATTERNS = [\n        '===', 'ITERATION', '--- Step', 'complete:', 'REFINEMENT COMPLETE',\n        'ERROR', 'Traceback', 'File \"', 'Error:', 'Running:', 'Resuming:',\n        'Total presentations', 'Greedy baseline', 'Resumed from',\n        'No previous state', 'Loading greedy', 'Converged', 'Interrupted',\n        'State saved', '[idx=', 'Search:',\n    ]\n\n    env = os.environ.copy()\n    env['PYTHONUNBUFFERED'] = '1'  # force line-by-line flushing in subprocess\n\n    proc = subprocess.Popen(\n        cmd, cwd=cwd,\n        stdout=subprocess.PIPE, stderr=subprocess.STDOUT,\n        text=True, bufsize=1, env=env,\n    )\n\n    last_was_progress = False\n    for raw in proc.stdout:\n        line = raw.rstrip()\n        if not line:\n            continue\n        is_header = any(p in line for p in HEADER_PATTERNS)\n        if is_header:\n            if last_was_progress:\n                sys.stdout.write('\\n')\n            print(line)\n            last_was_progress = False\n        else:\n            sys.stdout.write(f'\\r  {line:<90}')\n            sys.stdout.flush()\n            last_was_progress = True\n\n    if last_was_progress:\n        sys.stdout.write('\\n')\n    proc.wait()\n    return proc.returncode"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6 — Fresh Start\n",
    "Run this to begin a new refinement run from the greedy baseline. **Skip if resuming an existing run.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "cmd = [\n    sys.executable,\n    os.path.join(DRIVE_DIR, 'experiments/iterative_refinement.py'),\n    '--max-iterations', str(MAX_ITERATIONS),\n    '--max-path-length', str(MAX_PATH_LENGTH),\n    '--time-limit-per-pres', str(TIME_LIMIT_PER_PRES),\n]\nif MAX_NODES is not None:\n    cmd.extend(['--max-nodes', str(MAX_NODES)])\nif RUN_MLP:\n    cmd.append('--run-mlp')\nif not RUN_SEQ:\n    cmd.append('--no-seq')\nif ENABLE_MCTS:\n    cmd.append('--enable-mcts')\nif ENABLE_BEAM:\n    cmd.append('--enable-beam')\n\nprint('Running:', ' '.join(cmd))\nrc = run_with_progress(cmd, cwd=DRIVE_DIR)\nprint('Exit code:', rc)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7 — Reconstruct State (run only if state files are missing)\n",
    "Run this **only** when `refinement_state.json` is missing but partial search results exist on Drive (e.g. after accidentally deleting state or after a very early crash before any state was saved).  \n",
    "It auto-detects the latest partial results directory and rebuilds both state files.  \n",
    "Then run Cell 8 to continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using partial results dir: /content/drive/MyDrive/AC-Solver-Caltech/experiments/results/2026-02-26_04-06-25\n",
      "  Contains: 397 processed, 6 solved: [599, 689, 698, 711, 712, 834]\n",
      "Greedy paths loaded: 533\n",
      "Written: all_solved_paths.json (533 paths)\n",
      "Written: refinement_state.json\n",
      "\n",
      "Ready — run Cell 8 (Resume).\n"
     ]
    }
   ],
   "source": [
    "import os, sys, json\n",
    "\n",
    "sys.path.insert(0, DRIVE_DIR)\n",
    "from value_search.data_extraction import load_presentations, load_paths\n",
    "\n",
    "DATA_DIR       = os.path.join(DRIVE_DIR, 'ac_solver/search/miller_schupp/data')\n",
    "REFINEMENT_DIR = os.path.join(DRIVE_DIR, 'experiments/refinement')\n",
    "RESULTS_BASE   = os.path.join(DRIVE_DIR, 'experiments/results')\n",
    "os.makedirs(REFINEMENT_DIR, exist_ok=True)\n",
    "\n",
    "# 1. Auto-detect the latest partial results directory\n",
    "candidate_dirs = sorted([\n",
    "    d for d in os.listdir(RESULTS_BASE)\n",
    "    if os.path.isdir(os.path.join(RESULTS_BASE, d))\n",
    "    and os.path.exists(os.path.join(RESULTS_BASE, d, 'v_guided_greedy_progress.jsonl'))\n",
    "])\n",
    "if not candidate_dirs:\n",
    "    print(\"ERROR: No partial results found in\", RESULTS_BASE)\n",
    "    raise SystemExit\n",
    "\n",
    "PARTIAL_DIR = os.path.join(RESULTS_BASE, candidate_dirs[-1])\n",
    "print(f\"Using partial results dir: {PARTIAL_DIR}\")\n",
    "\n",
    "# Show what's in it\n",
    "jsonl = os.path.join(PARTIAL_DIR, 'v_guided_greedy_progress.jsonl')\n",
    "total, solved_indices = 0, []\n",
    "with open(jsonl) as f:\n",
    "    for line in f:\n",
    "        r = json.loads(line)\n",
    "        total += 1\n",
    "        if r.get('solved'):\n",
    "            solved_indices.append(r['idx'])\n",
    "print(f\"  Contains: {total} processed, {len(solved_indices)} solved: {solved_indices}\")\n",
    "\n",
    "# 2. Reload greedy paths from source data\n",
    "solved_pres = load_presentations(os.path.join(DATA_DIR, 'greedy_solved_presentations.txt'))\n",
    "raw_paths   = load_paths(os.path.join(DATA_DIR, 'greedy_search_paths.txt'))\n",
    "greedy_paths = {\n",
    "    tuple(pres): [[a - 1, l] for a, l in raw_path[1:]]\n",
    "    for pres, raw_path in zip(solved_pres, raw_paths)\n",
    "}\n",
    "print(f\"Greedy paths loaded: {len(greedy_paths)}\")\n",
    "\n",
    "# 3. Write all_solved_paths.json\n",
    "paths_file = os.path.join(REFINEMENT_DIR, 'all_solved_paths.json')\n",
    "with open(paths_file, 'w') as f:\n",
    "    json.dump({str(list(k)): v for k, v in greedy_paths.items()}, f)\n",
    "print(f\"Written: all_solved_paths.json ({len(greedy_paths)} paths)\")\n",
    "\n",
    "# 4. Write refinement_state.json pointing at partial results\n",
    "state = {\n",
    "    \"iteration\": 0,\n",
    "    \"solved_per_iteration\": [],\n",
    "    \"total_solved_per_iteration\": [len(greedy_paths)],\n",
    "    \"model_paths\": [],\n",
    "    \"results_dirs\": [PARTIAL_DIR],\n",
    "}\n",
    "state_file = os.path.join(REFINEMENT_DIR, 'refinement_state.json')\n",
    "with open(state_file, 'w') as f:\n",
    "    json.dump(state, f, indent=2)\n",
    "print(f\"Written: refinement_state.json\")\n",
    "print(f\"\\nReady — run Cell 8 (Resume).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8 — Resume After Disconnect\n",
    "After Colab disconnects: re-run Cells 1 → 2 → 3 → 5, then run this cell.  \n",
    "Picks up from the last completed iteration automatically — state persists on Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "cmd = [\n    sys.executable,\n    os.path.join(DRIVE_DIR, 'experiments/iterative_refinement.py'),\n    '--resume',\n    '--max-iterations', str(MAX_ITERATIONS),\n    '--max-path-length', str(MAX_PATH_LENGTH),\n    '--time-limit-per-pres', str(TIME_LIMIT_PER_PRES),\n]\nif MAX_NODES is not None:\n    cmd.extend(['--max-nodes', str(MAX_NODES)])\nif RUN_MLP:\n    cmd.append('--run-mlp')\nif not RUN_SEQ:\n    cmd.append('--no-seq')\nif ENABLE_MCTS:\n    cmd.append('--enable-mcts')\nif ENABLE_BEAM:\n    cmd.append('--enable-beam')\n\nprint('Resuming:', ' '.join(cmd))\nrc = run_with_progress(cmd, cwd=DRIVE_DIR)\nprint('Exit code:', rc)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cell 9 — Skip Iter 0 Search: Retrain & Advance to Iter 1\nRun this **instead of re-doing the iter 0 search** when the search is already complete\n(or close enough). It:\n1. Loads all solved paths (greedy seed + any solutions found in iter_0 results)\n2. Rebuilds training data with the correct `negative_label = 5 × MAX_PATH_LENGTH`\n3. Retrains both MLP and Seq models\n4. Advances state to `iteration=1` so Cell 8 (Resume) picks up from there"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import os, sys, json\nfrom ast import literal_eval\nsys.path.insert(0, DRIVE_DIR)\n\nfrom value_search.data_extraction import build_dataset_from_dict\nfrom value_search.benchmark import load_all_presentations\n\nREFINEMENT_DIR = os.path.join(DRIVE_DIR, 'experiments/refinement')\nall_presentations = load_all_presentations()\npres_by_idx = {i: tuple(p) for i, p in enumerate(all_presentations)}\n\n# 1. Load existing solved paths (greedy seed)\npaths_file = os.path.join(REFINEMENT_DIR, 'all_solved_paths.json')\nwith open(paths_file) as f:\n    raw = json.load(f)\nsolved_paths = {tuple(literal_eval(k)): v for k, v in raw.items()}\nprint(f'Loaded {len(solved_paths)} solved paths from all_solved_paths.json')\n\n# 2. Scan iter_0 search results and add any newly solved presentations\niter0_dir = os.path.join(REFINEMENT_DIR, 'iter_0')\nn_extra = 0\nif os.path.isdir(iter0_dir):\n    subdirs = sorted([\n        d for d in os.listdir(iter0_dir)\n        if os.path.isdir(os.path.join(iter0_dir, d)) and d[0].isdigit()\n    ])\n    if subdirs:\n        results_dir = os.path.join(iter0_dir, subdirs[-1])\n        jsonl_path = os.path.join(results_dir, 'v_guided_greedy_progress.jsonl')\n        if os.path.exists(jsonl_path):\n            with open(jsonl_path) as f:\n                for line in f:\n                    r = json.loads(line)\n                    if r.get('solved') and r.get('path'):\n                        pres_tuple = pres_by_idx[r['idx']]\n                        if pres_tuple not in solved_paths:\n                            solved_paths[pres_tuple] = r['path']\n                            n_extra += 1\n            print(f'Added {n_extra} new solutions from iter_0 search results')\n\n# 3. Save updated solved paths\nwith open(paths_file, 'w') as f:\n    json.dump({str(list(k)): v for k, v in solved_paths.items()}, f)\nprint(f'Total solved paths: {len(solved_paths)}')\n\n# 4. Build training data with corrected negative label (5x, not 2x)\nnegative_label = float(MAX_PATH_LENGTH * 5)\ndata_path = os.path.join(REFINEMENT_DIR, 'training_data_iter_0.pkl')\nbuild_dataset_from_dict(\n    solved_paths=solved_paths,\n    all_presentations=all_presentations,\n    output_path=data_path,\n    negative_label=negative_label,\n    max_path_length=MAX_PATH_LENGTH,\n)\nprint(f'Training data built with negative_label={negative_label}')\n\n# 5. Retrain both MLP and Seq\ncheckpoint_dir = os.path.join(REFINEMENT_DIR, 'checkpoints_iter_0')\ncmd = [\n    sys.executable,\n    os.path.join(DRIVE_DIR, 'value_search/train_value_net.py'),\n    '--data-path', data_path,\n    '--save-dir', checkpoint_dir,\n    '--architecture', 'both',\n    '--epochs', '100',\n]\nprint('Training...')\nrc = run_with_progress(cmd, cwd=DRIVE_DIR)\nif rc != 0:\n    print(f'ERROR: training failed (exit code {rc})')\n    raise SystemExit\n\n# 6. Verify checkpoint\nckpt = os.path.join(checkpoint_dir, 'best_mlp.pt')\nif not os.path.exists(ckpt):\n    print('ERROR: checkpoint not found!')\n    raise SystemExit\n\n# 7. Advance state to iteration=1\nstate_file = os.path.join(REFINEMENT_DIR, 'refinement_state.json')\nwith open(state_file) as f:\n    state = json.load(f)\n\nprev_total = state['total_solved_per_iteration'][-1] if state['total_solved_per_iteration'] else 0\ntotal_now = len(solved_paths)\nnew_count = total_now - prev_total\nstate['model_paths'].append(ckpt)\nstate['iteration'] = 1\nstate['solved_per_iteration'].append(new_count)\nstate['total_solved_per_iteration'].append(total_now)\n\nwith open(state_file, 'w') as f:\n    json.dump(state, f, indent=2)\n\nprint(f'\\nDone! State → iteration=1, total_solved={total_now} (+{new_count} new)')\nprint('Run Cell 8 (Resume) to continue from iteration 1.')\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 10 — Check Progress Anytime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n\nstate_file = os.path.join(DRIVE_DIR, 'experiments/refinement/refinement_state.json')\nif not os.path.exists(state_file):\n    print('No state file — run Cell 6 (fresh start) or Cell 7 (reconstruct state) first.')\nelse:\n    with open(state_file) as f:\n        state = json.load(f)\n\n    paths_file = os.path.join(DRIVE_DIR, 'experiments/refinement/all_solved_paths.json')\n    total_solved = 0\n    if os.path.exists(paths_file):\n        with open(paths_file) as f:\n            total_solved = len(json.load(f))\n\n    print(f'Current iteration:  {state[\"iteration\"]}')\n    print(f'Total solved:       {total_solved}/1190')\n    print(f'Solved per iter:    {state[\"solved_per_iteration\"]}')\n    print(f'Total per iter:     {state[\"total_solved_per_iteration\"]}')\n\n    refinement_dir = os.path.join(DRIVE_DIR, 'experiments/refinement')\n    print(f'\\nFiles in refinement dir:')\n    for f in sorted(os.listdir(refinement_dir)):\n        fpath = os.path.join(refinement_dir, f)\n        size_mb = os.path.getsize(fpath) / 1e6 if os.path.isfile(fpath) else 0\n        tag = f'({size_mb:.1f} MB)' if os.path.isfile(fpath) else '(dir)'\n        print(f'  {f}  {tag}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
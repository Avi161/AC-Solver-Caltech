{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AC-Solver Iterative Refinement — Colab Runner\n",
    "\n",
    "**Runtime recommendation: High-RAM CPU**  \n",
    "The search (V-guided greedy, beam) is CPU-only. GPU only helps training, which takes ~10 min per iteration — not the bottleneck.\n",
    "\n",
    "**Persistence:** Repo lives on Google Drive. If Colab disconnects, re-run cells 1–3 (fast), then Cell 6 to resume."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1 — Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "print('Drive mounted.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2 — Clone or Update Repo on Drive\n",
    "\n",
    "**First time only:** enter your GitHub Personal Access Token when prompted.  \n",
    "Get one at: GitHub → Settings → Developer Settings → Personal access tokens → Fine-grained → repo read access.  \n",
    "After first clone, this cell just does `git pull`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "REPO_URL = 'https://github.com/Avi161/AC-Solver-Caltech.git'\n",
    "DRIVE_DIR = '/content/drive/MyDrive/AC-Solver-Caltech'\n",
    "\n",
    "if not os.path.exists(DRIVE_DIR):\n",
    "    # First time: clone with token\n",
    "    from getpass import getpass\n",
    "    token = getpass('GitHub Personal Access Token: ')\n",
    "    auth_url = REPO_URL.replace('https://', f'https://{token}@')\n",
    "    subprocess.run(['git', 'clone', auth_url, DRIVE_DIR], check=True)\n",
    "    print('Repo cloned to Drive.')\n",
    "else:\n",
    "    # Already cloned: just pull latest changes\n",
    "    result = subprocess.run(['git', 'pull'], cwd=DRIVE_DIR, capture_output=True, text=True)\n",
    "    print(result.stdout or 'Already up to date.')\n",
    "\n",
    "os.chdir(DRIVE_DIR)\n",
    "print(f'Working directory: {os.getcwd()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3 — Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "result = subprocess.run(\n",
    "    ['pip', 'install', '-q', '-r', 'requirements.txt'],\n",
    "    cwd=DRIVE_DIR, capture_output=True, text=True\n",
    ")\n",
    "print(result.stdout[-2000:] if result.stdout else 'Done.')\n",
    "if result.returncode != 0:\n",
    "    print('ERRORS:', result.stderr[-1000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4 — Verify Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "\n",
    "checks = {\n",
    "    'Original model checkpoint':  'value_search/checkpoints/best_mlp.pt',\n",
    "    'Feature stats':              'value_search/checkpoints/feature_stats.json',\n",
    "    'Greedy solved presentations': 'ac_solver/search/miller_schupp/data/greedy_solved_presentations.txt',\n",
    "    'Greedy search paths':         'ac_solver/search/miller_schupp/data/greedy_search_paths.txt',\n",
    "    'Config':                      'experiments/config.yaml',\n",
    "}\n",
    "\n",
    "all_ok = True\n",
    "for label, path in checks.items():\n",
    "    full = os.path.join(DRIVE_DIR, path)\n",
    "    exists = os.path.exists(full)\n",
    "    status = '✓' if exists else '✗  MISSING'\n",
    "    print(f'  {status}  {label}')\n",
    "    if not exists:\n",
    "        all_ok = False\n",
    "\n",
    "# Check refinement state (if resuming)\n",
    "state_file = os.path.join(DRIVE_DIR, 'experiments/refinement/refinement_state.json')\n",
    "if os.path.exists(state_file):\n",
    "    with open(state_file) as f:\n",
    "        state = json.load(f)\n",
    "    print(f'\\n  Saved state found: iteration={state[\"iteration\"]}, '\n",
    "          f'total_solved_history={state[\"total_solved_per_iteration\"]}')\n",
    "else:\n",
    "    print('\\n  No saved state — will start fresh.')\n",
    "\n",
    "if all_ok:\n",
    "    print('\\nAll checks passed. Ready to run.')\n",
    "else:\n",
    "    print('\\nFix missing files before running.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5 — Configuration\n",
    "Edit these before running. Then run Cell 6 (fresh start) or Cell 7 (resume)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Tune these ────────────────────────────────────────────────────────────────\n",
    "MAX_ITERATIONS  = 5       # How many search→train cycles\n",
    "MAX_PATH_LENGTH = 300     # Reject training paths longer than this\n",
    "ENABLE_MCTS     = False   # MCTS is slow; keep False unless you have many hours\n",
    "\n",
    "# Set to an integer (e.g. 100_000) to cap search budget for a quick smoke test.\n",
    "# Set to None for full 1M-node search.\n",
    "MAX_NODES = None\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, DRIVE_DIR)\n",
    "\n",
    "print('Config set:')\n",
    "print(f'  max_iterations  = {MAX_ITERATIONS}')\n",
    "print(f'  max_path_length = {MAX_PATH_LENGTH}')\n",
    "print(f'  enable_mcts     = {ENABLE_MCTS}')\n",
    "print(f'  max_nodes       = {MAX_NODES if MAX_NODES else \"1,000,000 (default)\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6 — Fresh Start\n",
    "Run this if you have no previous state (first time ever).  \n",
    "**Skip this if resuming — use Cell 7 instead.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = [\n",
    "    sys.executable,\n",
    "    os.path.join(DRIVE_DIR, 'experiments/iterative_refinement.py'),\n",
    "    '--max-iterations', str(MAX_ITERATIONS),\n",
    "    '--max-path-length', str(MAX_PATH_LENGTH),\n",
    "]\n",
    "if ENABLE_MCTS:\n",
    "    cmd.append('--enable-mcts')\n",
    "if MAX_NODES is not None:\n",
    "    cmd.extend(['--max-nodes', str(MAX_NODES)])\n",
    "\n",
    "print('Running:', ' '.join(cmd))\n",
    "import subprocess\n",
    "result = subprocess.run(cmd, cwd=DRIVE_DIR)\n",
    "print('Exit code:', result.returncode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7 — Resume After Disconnect\n",
    "After Colab disconnects: re-run Cells 1–3 (takes ~1 min), configure Cell 5, then run this cell.  \n",
    "It picks up from the last completed iteration automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = [\n",
    "    sys.executable,\n",
    "    os.path.join(DRIVE_DIR, 'experiments/iterative_refinement.py'),\n",
    "    '--resume',\n",
    "    '--max-iterations', str(MAX_ITERATIONS),\n",
    "    '--max-path-length', str(MAX_PATH_LENGTH),\n",
    "]\n",
    "if ENABLE_MCTS:\n",
    "    cmd.append('--enable-mcts')\n",
    "if MAX_NODES is not None:\n",
    "    cmd.extend(['--max-nodes', str(MAX_NODES)])\n",
    "\n",
    "print('Resuming:', ' '.join(cmd))\n",
    "import subprocess\n",
    "result = subprocess.run(cmd, cwd=DRIVE_DIR)\n",
    "print('Exit code:', result.returncode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8 — Check Progress Anytime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "\n",
    "state_file = os.path.join(DRIVE_DIR, 'experiments/refinement/refinement_state.json')\n",
    "if not os.path.exists(state_file):\n",
    "    print('No state file yet — run Cell 6 first.')\n",
    "else:\n",
    "    with open(state_file) as f:\n",
    "        state = json.load(f)\n",
    "\n",
    "    paths_file = os.path.join(DRIVE_DIR, 'experiments/refinement/all_solved_paths.json')\n",
    "    total_solved = 0\n",
    "    if os.path.exists(paths_file):\n",
    "        with open(paths_file) as f:\n",
    "            total_solved = len(json.load(f))\n",
    "\n",
    "    print(f'Current iteration:  {state[\"iteration\"]}')\n",
    "    print(f'Total solved:       {total_solved}/1190')\n",
    "    print(f'Solved per iter:    {state[\"solved_per_iteration\"]}')\n",
    "    print(f'Total per iter:     {state[\"total_solved_per_iteration\"]}')\n",
    "\n",
    "    refinement_dir = os.path.join(DRIVE_DIR, 'experiments/refinement')\n",
    "    print(f'\\nFiles in refinement dir:')\n",
    "    for f in sorted(os.listdir(refinement_dir)):\n",
    "        fpath = os.path.join(refinement_dir, f)\n",
    "        size_mb = os.path.getsize(fpath) / 1e6 if os.path.isfile(fpath) else 0\n",
    "        tag = f'({size_mb:.1f} MB)' if os.path.isfile(fpath) else '(dir)'\n",
    "        print(f'  {f}  {tag}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

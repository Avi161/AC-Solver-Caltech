# ============================================================
# AC-Solver Experiment Configuration
# ============================================================
#
# HOW TO RUN:
#   python experiments/run_experiments.py                    # full run from this config
#   python experiments/run_experiments.py --max-nodes 10000  # quick test (overrides ALL algorithms)
#   python experiments/run_experiments.py --config my.yaml   # use a different config file
#
# ============================================================

# --- Output ---
output_dir: "experiments/results"
save_incremental: true

resume_dir: ""
#   - Set to "" for a fresh run (creates new timestamped directory)
#   - Set to a previous results dir to resume from where it left off, e.g.:
#     resume_dir: ""

solution_cache_path: ""
#   - Set to "" to disable caching entirely or "experiments/solution_cache.pkl"

# --- Device ---
device: "auto"
# ^ "auto" = use GPU if available, else CPU

# --- Model (for V-guided, Beam, and MCTS only) ---
# Greedy and BFS are model-free baselines;
model:
  architecture: "mlp"
  # ^ Which value network architecture to use:
  #   "mlp" = Multi-Layer Perceptron (simple, fast, slightly less accurate)
  #           - Uses hand-crafted features (relator lengths, etc.)
  #           - Checkpoint: value_search/checkpoints/best_mlp.pt
  #   "seq" = Sequence Conv1D model (slower per inference, more accurate)
  #           - Reads raw relator tokens directly via 1D convolutions
  #           - Checkpoint: value_search/checkpoints/best_seq.pt

  checkpoint: "value_search/checkpoints/best_mlp.pt"
  # ^ Path to the trained model weights. Available checkpoints:
  #   value_search/checkpoints/best_mlp.pt  (use with architecture: "mlp")
  #   value_search/checkpoints/best_seq.pt  (use with architecture: "seq")

  feature_stats: "value_search/checkpoints/feature_stats.json"
  # ^ Normalization stats (mean/std) computed from training data.
  #   Same file works for both mlp and seq. Don't change this.

algorithms:
  # ---- Paper baselines (no ML model needed) ----

  greedy:
    enabled: false
    max_nodes: 1_000_000

  bfs:
    enabled: false
    max_nodes: 1_000_000

  # ---- Our methods (require a trained model) ----

  v_guided_greedy:
    enabled: true
    max_nodes: 1_000_000 # Same budget for fair comparison
    cyclically_reduce: true # Apply cyclic reduction after each AC move

  beam_search:
    enabled: false
    max_nodes: 1_000_000
    beam_widths: [10, 50]

  mcts:
    enabled: false # Very slow -- enable only if you have 8+ hours
    max_nodes: 100_000
    c_explore: 1.41

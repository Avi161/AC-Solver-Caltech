{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# AC-Solver: Parallelized Value-Guided Search on A100\n",
    "\n",
    "This notebook runs V-guided greedy, beam search, and MCTS on **all 1190 Miller-Schupp presentations** using multiprocessing + A100 GPU.\n",
    "\n",
    "**Runtime setup**: Go to `Runtime > Change runtime type > A100 GPU`\n",
    "\n",
    "**Expected runtime**: ~30-60 min for V-guided at 1M nodes, ~2-4h for all three algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## 1. Setup: Clone Repo and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf755952",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clone-repo",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('/content/AC-Solver-Caltech'):\n",
    "    !git clone https://github.com/Avi161/AC-Solver-Caltech.git\n",
    "%cd /content/AC-Solver-Caltech\n",
    "!git fetch origin\n",
    "!git checkout feat/test-antigravity\n",
    "!git pull origin feat/test-antigravity\n",
    "!pip install -q torch numpy pyyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verify-gpu",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "# NOTE: Do NOT call torch.cuda.get_device_name() or get_device_properties()\n",
    "# here. Those calls initialize CUDA in the main process, which breaks\n",
    "# fork-based multiprocessing later. GPU will be used inside workers.\n",
    "if not torch.cuda.is_available():\n",
    "    print(\"WARNING: No GPU detected! Go to Runtime > Change runtime type > A100 GPU\")\n",
    "\n",
    "import multiprocessing\n",
    "print(f\"CPU cores: {multiprocessing.cpu_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verify-checkpoints",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Verify that model checkpoints exist\n",
    "for f in ['value_search/checkpoints/best_mlp.pt',\n",
    "          'value_search/checkpoints/best_seq.pt',\n",
    "          'value_search/checkpoints/feature_stats.json']:\n",
    "    exists = os.path.exists(f)\n",
    "    size = os.path.getsize(f) if exists else 0\n",
    "    print(f\"  {'\u2713' if exists else '\u2717'} {f} ({size/1024:.0f} KB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "Adjust these settings based on how long you want to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CONFIGURATION \u2014 adjust these as needed\n",
    "# ============================================================\n",
    "\n",
    "# Which algorithms to run. Options: 'v_guided', 'beam', 'mcts', or 'all'\n",
    "ALGORITHM = 'all'\n",
    "\n",
    "# Value network architecture: 'mlp' (faster) or 'seq' (more accurate)\n",
    "ARCHITECTURE = 'mlp'\n",
    "\n",
    "# Max nodes to explore per presentation per algorithm.\n",
    "# Recommended budgets:\n",
    "#   1,000   -> ~30s total, quick sanity check\n",
    "#   10,000  -> ~5 min total\n",
    "#   100,000 -> ~30-60 min for v_guided, much longer for MCTS\n",
    "#   1,000,000 -> ~4-8h for v_guided (best results)\n",
    "MAX_NODES = 1_000_000\n",
    "\n",
    "# Number of parallel worker processes.\n",
    "# A100 Colab has ~12 CPU cores. Workers run search in parallel.\n",
    "# Each worker loads its own copy of the model onto the GPU.\n",
    "# Recommended: 6-8 for A100 (balance CPU search + GPU inference)\n",
    "NUM_WORKERS = 8\n",
    "\n",
    "# Beam width (only for beam search)\n",
    "BEAM_WIDTH = 50\n",
    "\n",
    "# MCTS exploration constant\n",
    "C_EXPLORE = 1.41\n",
    "\n",
    "# Apply cyclic reduction after AC moves (slightly better results)\n",
    "CYCLICALLY_REDUCE = True\n",
    "\n",
    "print(f\"Config: algorithm={ALGORITHM}, arch={ARCHITECTURE}, \"\n",
    "      f\"max_nodes={MAX_NODES:,}, workers={NUM_WORKERS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "run-header",
   "metadata": {},
   "source": [
    "## 3. Run Parallel Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "\n",
    "import multiprocessing\n",
    "multiprocessing.set_start_method('spawn', force=True)\n",
    "from multiprocessing import Pool\n",
    "\n",
    "sys.path.insert(0, '.')\n",
    "\n",
    "from ac_solver.envs.ac_moves import ACMove\n",
    "from ac_solver.envs.utils import is_presentation_trivial\n",
    "from value_search.value_guided_search import (\n",
    "    value_guided_greedy_search, beam_search, load_model,\n",
    "    backfill_solution_cache,\n",
    ")\n",
    "from value_search.mcts import mcts_search\n",
    "\n",
    "# Import worker function from .py file (required for spawn)\n",
    "from scripts.colab_worker import search_worker\n",
    "\n",
    "print(\"Imports OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all presentations\n",
    "def load_presentations(path):\n",
    "    pres = []\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                pres.append(np.array(literal_eval(line.strip()), dtype=np.int8))\n",
    "    return pres\n",
    "\n",
    "all_pres = load_presentations('ac_solver/search/miller_schupp/data/all_presentations.txt')\n",
    "greedy_solved_pres = load_presentations('ac_solver/search/miller_schupp/data/greedy_solved_presentations.txt')\n",
    "greedy_solved_set = set(tuple(p) for p in greedy_solved_pres)\n",
    "\n",
    "print(f\"Total presentations: {len(all_pres)}\")\n",
    "print(f\"Greedy solved: {len(greedy_solved_set)}\")\n",
    "print(f\"Unsolved by greedy: {len(all_pres) - len(greedy_solved_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worker-func",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_worker is imported from scripts/colab_worker.py above.\n",
    "# It must live in a .py file (not a notebook cell) because the 'spawn'\n",
    "# start method creates fresh Python processes that need to import\n",
    "# the worker function by module path.\n",
    "print(f\"Worker function: {search_worker.__module__}.{search_worker.__name__}\")\n",
    "print(\"Worker function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_parallel(presentations, algorithm, config, num_workers, greedy_solved_set):\n",
    "    \"\"\"Run search in parallel across all presentations.\"\"\"\n",
    "    n = len(presentations)\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"  {algorithm.upper()} | {config['max_nodes']:,} nodes | {num_workers} workers\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    work_items = [\n",
    "        (i, pres.tolist(), algorithm, config)\n",
    "        for i, pres in enumerate(presentations)\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    solved_count = 0\n",
    "    newly_solved_count = 0\n",
    "    t_start = time.time()\n",
    "    \n",
    "    with Pool(processes=num_workers) as pool:\n",
    "        for result in pool.imap_unordered(search_worker, work_items):\n",
    "            results.append(result)\n",
    "            if result['solved']:\n",
    "                solved_count += 1\n",
    "                if tuple(presentations[result['idx']]) not in greedy_solved_set:\n",
    "                    newly_solved_count += 1\n",
    "            \n",
    "            done = len(results)\n",
    "            if done % 1 == 0 or done == n:\n",
    "                elapsed = time.time() - t_start\n",
    "                rate = elapsed / done\n",
    "                eta = rate * (n - done)\n",
    "                eta_s = f\"{eta/60:.1f}m\" if eta < 3600 else f\"{eta/3600:.1f}h\"\n",
    "                print(f\"  {done}/{n} | solved={solved_count} | \"\n",
    "                      f\"new={newly_solved_count} | ETA {eta_s}\")\n",
    "    \n",
    "    total_time = time.time() - t_start\n",
    "    results.sort(key=lambda r: r['idx'])\n",
    "    \n",
    "    solved_results = [r for r in results if r['solved']]\n",
    "    path_lengths = [r['path_length'] for r in solved_results]\n",
    "    \n",
    "    print(f\"\\n  RESULT: {len(solved_results)}/{n} solved \"\n",
    "          f\"({newly_solved_count} new beyond greedy) in {total_time/60:.1f}m\")\n",
    "    if path_lengths:\n",
    "        print(f\"  Avg path: {np.mean(path_lengths):.1f}, \"\n",
    "              f\"Max: {max(path_lengths)}, Min: {min(path_lengths)}\")\n",
    "    \n",
    "    # Show newly solved\n",
    "    newly = [r for r in solved_results \n",
    "             if tuple(presentations[r['idx']]) not in greedy_solved_set]\n",
    "    if newly:\n",
    "        print(f\"\\n  *** NEWLY SOLVED ({len(newly)} presentations) ***\")\n",
    "        for r in newly[:30]:\n",
    "            pres = presentations[r['idx']]\n",
    "            mrl = len(pres) // 2\n",
    "            tl = int(np.count_nonzero(pres[:mrl]) + np.count_nonzero(pres[mrl:]))\n",
    "            print(f\"    idx={r['idx']:>4d}, path_len={r['path_length']:>3d}, \"\n",
    "                  f\"word_len={tl}, nodes={r['nodes_explored']:>7d}\")\n",
    "        if len(newly) > 30:\n",
    "            print(f\"    ... and {len(newly)-30} more\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Build config\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "arch = ARCHITECTURE\n",
    "ckpt = f'value_search/checkpoints/best_{arch}.pt'\n",
    "stats = 'value_search/checkpoints/feature_stats.json'\n",
    "\n",
    "config = {\n",
    "    'device': device,\n",
    "    'architecture': arch,\n",
    "    'checkpoint': ckpt,\n",
    "    'feature_stats': stats,\n",
    "    'max_nodes': MAX_NODES,\n",
    "    'beam_width': BEAM_WIDTH,\n",
    "    'c_explore': C_EXPLORE,\n",
    "    'cyclically_reduce': CYCLICALLY_REDUCE,\n",
    "}\n",
    "\n",
    "# Determine algorithms\n",
    "if ALGORITHM == 'all':\n",
    "    algos = ['v_guided', 'beam', 'mcts']\n",
    "else:\n",
    "    algos = [ALGORITHM]\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Algorithms to run: {algos}\")\n",
    "print(f\"Starting...\")\n",
    "\n",
    "all_results = {}\n",
    "all_solved_sets = {}\n",
    "\n",
    "for algo in algos:\n",
    "    results = run_parallel(all_pres, algo, config, NUM_WORKERS, greedy_solved_set)\n",
    "    all_results[algo] = results\n",
    "    all_solved_sets[algo] = set(r['idx'] for r in results if r['solved'])\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"  ALL DONE\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analysis-header",
   "metadata": {},
   "source": [
    "## 4. Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison table\n",
    "print(f\"{'Algorithm':<20} | {'Solved':>10} | {'New':>5} | {'Avg Path':>10} | {'Max Path':>10}\")\n",
    "print(f\"{'-'*20}-+-{'-'*10}-+-{'-'*5}-+-{'-'*10}-+-{'-'*10}\")\n",
    "\n",
    "for algo, results in all_results.items():\n",
    "    solved = [r for r in results if r['solved']]\n",
    "    newly = [r for r in solved if tuple(all_pres[r['idx']]) not in greedy_solved_set]\n",
    "    paths = [r['path_length'] for r in solved]\n",
    "    avg_p = f\"{np.mean(paths):.1f}\" if paths else \"\u2014\"\n",
    "    max_p = f\"{max(paths)}\" if paths else \"\u2014\"\n",
    "    print(f\"{algo:<20} | {f'{len(solved)}/1190':>10} | {len(newly):>5} | {avg_p:>10} | {max_p:>10}\")\n",
    "\n",
    "# Union\n",
    "if len(all_solved_sets) > 1:\n",
    "    union = set()\n",
    "    for s in all_solved_sets.values():\n",
    "        union |= s\n",
    "    union_new = sum(1 for idx in union if tuple(all_pres[idx]) not in greedy_solved_set)\n",
    "    print(f\"{'UNION':<20} | {f'{len(union)}/1190':>10} | {union_new:>5} |\")\n",
    "    \n",
    "    # Uniquely solved by each\n",
    "    print(f\"\\nUniquely solved:\")\n",
    "    for algo, s in all_solved_sets.items():\n",
    "        others = set().union(*(v for k, v in all_solved_sets.items() if k != algo))\n",
    "        unique = s - others\n",
    "        if unique:\n",
    "            print(f\"  {algo}: {len(unique)} unique\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all results\n",
    "timestamp = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "output_dir = f'experiments/results/{timestamp}_colab'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save config\n",
    "with open(f'{output_dir}/config.json', 'w') as f:\n",
    "    json.dump({\n",
    "        'algorithms': algos,\n",
    "        'max_nodes': MAX_NODES,\n",
    "        'workers': NUM_WORKERS,\n",
    "        'architecture': ARCHITECTURE,\n",
    "        'beam_width': BEAM_WIDTH,\n",
    "        'c_explore': C_EXPLORE,\n",
    "        'device': device,\n",
    "    }, f, indent=2)\n",
    "\n",
    "# Save per-algorithm results\n",
    "for algo, results in all_results.items():\n",
    "    with open(f'{output_dir}/{algo}_results.json', 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "\n",
    "# Save newly solved summary\n",
    "all_newly = {}\n",
    "for algo, results in all_results.items():\n",
    "    newly = [r for r in results if r['solved'] \n",
    "             and tuple(all_pres[r['idx']]) not in greedy_solved_set]\n",
    "    all_newly[algo] = [r['idx'] for r in newly]\n",
    "\n",
    "with open(f'{output_dir}/newly_solved.json', 'w') as f:\n",
    "    json.dump(all_newly, f, indent=2)\n",
    "\n",
    "print(f\"Results saved to: {output_dir}/\")\n",
    "print(f\"Files:\")\n",
    "for fname in sorted(os.listdir(output_dir)):\n",
    "    size = os.path.getsize(f'{output_dir}/{fname}')\n",
    "    print(f\"  {fname} ({size/1024:.0f} KB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verify-header",
   "metadata": {},
   "source": [
    "## 5. Verify Newly Solved Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verify-paths",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that all reported solutions are actually correct\n",
    "def verify_solution(pres, path):\n",
    "    \"\"\"Replay path and verify it reaches trivial.\"\"\"\n",
    "    state = np.array(pres, dtype=np.int8)\n",
    "    mrl = len(state) // 2\n",
    "    wl = [int(np.count_nonzero(state[:mrl])), int(np.count_nonzero(state[mrl:]))]\n",
    "    for action, expected_len in path:\n",
    "        state, wl = ACMove(action, state, mrl, wl, cyclical=False)\n",
    "    return is_presentation_trivial(state)\n",
    "\n",
    "print(\"Verifying all solutions...\")\n",
    "errors = 0\n",
    "verified = 0\n",
    "for algo, results in all_results.items():\n",
    "    for r in results:\n",
    "        if r['solved'] and 'path' in r:\n",
    "            path = [(a, l) for a, l in r['path']]\n",
    "            ok = verify_solution(all_pres[r['idx']], path)\n",
    "            if not ok:\n",
    "                print(f\"  ERROR: {algo} idx={r['idx']} path does NOT reach trivial!\")\n",
    "                errors += 1\n",
    "            verified += 1\n",
    "\n",
    "print(f\"Verified {verified} solutions, {errors} errors\")\n",
    "if errors == 0:\n",
    "    print(\"All solutions are verified correct! \u2713\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "download-header",
   "metadata": {},
   "source": [
    "## 6. Download Results (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "download",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip results for download\n",
    "import shutil\n",
    "zip_path = shutil.make_archive(f'/content/ac_solver_results_{timestamp}', 'zip', output_dir)\n",
    "print(f\"Results zipped to: {zip_path}\")\n",
    "\n",
    "# If running on Colab, offer download\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download(zip_path)\n",
    "except ImportError:\n",
    "    print(\"Not on Colab \u2014 download manually from the file browser.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# AC-Solver: Parallelized Value-Guided Search on A100\n",
    "\n",
    "This notebook runs V-guided greedy, beam search, and MCTS on **all 1190 Miller-Schupp presentations** using multiprocessing + A100 GPU.\n",
    "\n",
    "**Runtime setup**: Go to `Runtime > Change runtime type > A100 GPU`\n",
    "\n",
    "**Expected runtime**: ~30-60 min for V-guided at 1M nodes, ~2-4h for all three algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## 1. Setup: Clone Repo and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf755952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "clone-repo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/AC-Solver-Caltech\n",
      "Already on 'feat/test-antigravity'\n",
      "Your branch is up to date with 'origin/feat/test-antigravity'.\n",
      "From https://github.com/Avi161/AC-Solver-Caltech\n",
      " * branch            feat/test-antigravity -> FETCH_HEAD\n",
      "Already up to date.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if not os.path.exists('/content/AC-Solver-Caltech'):\n",
    "    !git clone https://github.com/Avi161/AC-Solver-Caltech.git\n",
    "%cd /content/AC-Solver-Caltech\n",
    "!git fetch origin\n",
    "!git checkout feat/test-antigravity\n",
    "!git pull origin feat/test-antigravity\n",
    "!pip install -q torch numpy pyyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "verify-gpu",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.10.0+cu128\n",
      "CUDA available: True\n",
      "CPU cores: 12\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "# NOTE: Do NOT call torch.cuda.get_device_name() or get_device_properties()\n",
    "# here. Those calls initialize CUDA in the main process, which breaks\n",
    "# fork-based multiprocessing later. GPU will be used inside workers.\n",
    "if not torch.cuda.is_available():\n",
    "    print(\"WARNING: No GPU detected! Go to Runtime > Change runtime type > A100 GPU\")\n",
    "\n",
    "import multiprocessing\n",
    "print(f\"CPU cores: {multiprocessing.cpu_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "verify-checkpoints",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \u2713 value_search/checkpoints/best_mlp.pt (405 KB)\n",
      "  \u2713 value_search/checkpoints/best_seq.pt (159 KB)\n",
      "  \u2713 value_search/checkpoints/feature_stats.json (1 KB)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Verify that model checkpoints exist\n",
    "for f in ['value_search/checkpoints/best_mlp.pt',\n",
    "          'value_search/checkpoints/best_seq.pt',\n",
    "          'value_search/checkpoints/feature_stats.json']:\n",
    "    exists = os.path.exists(f)\n",
    "    size = os.path.getsize(f) if exists else 0\n",
    "    print(f\"  {'\u2713' if exists else '\u2717'} {f} ({size/1024:.0f} KB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "Adjust these settings based on how long you want to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "config",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: algorithm=all, arch=mlp, max_nodes=1,000,000, workers=8\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CONFIGURATION \u2014 adjust these as needed\n",
    "# ============================================================\n",
    "\n",
    "# Which algorithms to run. Options: 'v_guided', 'beam', 'mcts', or 'all'\n",
    "ALGORITHM = 'all'\n",
    "\n",
    "# Value network architecture: 'mlp' (faster) or 'seq' (more accurate)\n",
    "ARCHITECTURE = 'mlp'\n",
    "\n",
    "# Max nodes to explore per presentation per algorithm.\n",
    "# Recommended budgets:\n",
    "#   1,000   -> ~30s total, quick sanity check\n",
    "#   10,000  -> ~5 min total\n",
    "#   100,000 -> ~30-60 min for v_guided, much longer for MCTS\n",
    "#   1,000,000 -> ~4-8h for v_guided (best results)\n",
    "MAX_NODES = 1_000_000\n",
    "\n",
    "# Number of parallel worker processes.\n",
    "# A100 Colab has ~12 CPU cores. Workers run search in parallel.\n",
    "# Each worker loads its own copy of the model onto the GPU.\n",
    "# Recommended: 6-8 for A100 (balance CPU search + GPU inference)\n",
    "NUM_WORKERS = 8\n",
    "\n",
    "# Beam width (only for beam search)\n",
    "BEAM_WIDTH = 50\n",
    "\n",
    "# MCTS exploration constant\n",
    "C_EXPLORE = 1.41\n",
    "\n",
    "# Apply cyclic reduction after AC moves (slightly better results)\n",
    "CYCLICALLY_REDUCE = True\n",
    "\n",
    "print(f\"Config: algorithm={ALGORITHM}, arch={ARCHITECTURE}, \"\n",
    "      f\"max_nodes={MAX_NODES:,}, workers={NUM_WORKERS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "run-header",
   "metadata": {},
   "source": [
    "## 3. Run Parallel Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports OK\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "\n",
    "import multiprocessing\n",
    "multiprocessing.set_start_method('spawn', force=True)\n",
    "from multiprocessing import Pool\n",
    "\n",
    "sys.path.insert(0, '.')\n",
    "\n",
    "from ac_solver.envs.ac_moves import ACMove\n",
    "from ac_solver.envs.utils import is_presentation_trivial\n",
    "from value_search.value_guided_search import (\n",
    "    value_guided_greedy_search, beam_search, load_model,\n",
    "    backfill_solution_cache,\n",
    ")\n",
    "from value_search.mcts import mcts_search\n",
    "\n",
    "# Import worker function from .py file (required for spawn)\n",
    "from scripts.colab_worker import search_worker\n",
    "\n",
    "print(\"Imports OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "load-data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total presentations: 1190\n",
      "Greedy solved: 533\n",
      "Unsolved by greedy: 657\n"
     ]
    }
   ],
   "source": [
    "# Load all presentations\n",
    "def load_presentations(path):\n",
    "    pres = []\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                pres.append(np.array(literal_eval(line.strip()), dtype=np.int8))\n",
    "    return pres\n",
    "\n",
    "all_pres = load_presentations('ac_solver/search/miller_schupp/data/all_presentations.txt')\n",
    "greedy_solved_pres = load_presentations('ac_solver/search/miller_schupp/data/greedy_solved_presentations.txt')\n",
    "greedy_solved_set = set(tuple(p) for p in greedy_solved_pres)\n",
    "\n",
    "print(f\"Total presentations: {len(all_pres)}\")\n",
    "print(f\"Greedy solved: {len(greedy_solved_set)}\")\n",
    "print(f\"Unsolved by greedy: {len(all_pres) - len(greedy_solved_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "worker-func",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker function: scripts.colab_worker.search_worker\n",
      "Worker function ready\n"
     ]
    }
   ],
   "source": [
    "# search_worker is imported from scripts/colab_worker.py above.\n",
    "# It must live in a .py file (not a notebook cell) because the 'spawn'\n",
    "# start method creates fresh Python processes that need to import\n",
    "# the worker function by module path.\n",
    "print(f\"Worker function: {search_worker.__module__}.{search_worker.__name__}\")\n",
    "print(\"Worker function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "run-search",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Algorithms to run: ['v_guided', 'beam', 'mcts']\n",
      "Starting...\n",
      "\n",
      "============================================================\n",
      "  V_GUIDED | 1,000 nodes | 8 workers\n",
      "============================================================\n",
      "  1/1190 | solved=1 | new=0 | ETA 1.3h\n",
      "  2/1190 | solved=2 | new=0 | ETA 39.4m\n",
      "  3/1190 | solved=3 | new=0 | ETA 26.7m\n",
      "  4/1190 | solved=4 | new=0 | ETA 20.2m\n",
      "  5/1190 | solved=5 | new=0 | ETA 16.3m\n",
      "  6/1190 | solved=6 | new=0 | ETA 13.7m\n",
      "  7/1190 | solved=7 | new=0 | ETA 11.8m\n",
      "  8/1190 | solved=8 | new=0 | ETA 10.3m\n",
      "  9/1190 | solved=9 | new=0 | ETA 9.2m\n",
      "  10/1190 | solved=10 | new=0 | ETA 8.3m\n",
      "  11/1190 | solved=11 | new=0 | ETA 7.6m\n",
      "  12/1190 | solved=12 | new=0 | ETA 7.4m\n",
      "  13/1190 | solved=13 | new=0 | ETA 6.9m\n",
      "  14/1190 | solved=14 | new=0 | ETA 6.5m\n",
      "  15/1190 | solved=15 | new=0 | ETA 6.0m\n",
      "  16/1190 | solved=16 | new=0 | ETA 5.7m\n",
      "  17/1190 | solved=17 | new=0 | ETA 5.3m\n",
      "  18/1190 | solved=18 | new=0 | ETA 5.1m\n",
      "  19/1190 | solved=19 | new=0 | ETA 4.8m\n",
      "  20/1190 | solved=20 | new=0 | ETA 4.6m\n",
      "  21/1190 | solved=21 | new=0 | ETA 4.4m\n",
      "  22/1190 | solved=22 | new=0 | ETA 4.2m\n",
      "  23/1190 | solved=23 | new=0 | ETA 4.0m\n",
      "  24/1190 | solved=24 | new=0 | ETA 3.9m\n",
      "  25/1190 | solved=25 | new=0 | ETA 3.8m\n",
      "  26/1190 | solved=26 | new=0 | ETA 3.7m\n",
      "  27/1190 | solved=27 | new=0 | ETA 3.5m\n",
      "  28/1190 | solved=28 | new=0 | ETA 3.4m\n",
      "  29/1190 | solved=29 | new=0 | ETA 3.3m\n",
      "  30/1190 | solved=30 | new=0 | ETA 3.2m\n",
      "  31/1190 | solved=31 | new=0 | ETA 3.1m\n",
      "  32/1190 | solved=32 | new=0 | ETA 3.0m\n",
      "  33/1190 | solved=33 | new=0 | ETA 3.0m\n",
      "  34/1190 | solved=34 | new=0 | ETA 2.9m\n",
      "  35/1190 | solved=35 | new=0 | ETA 2.8m\n",
      "  36/1190 | solved=36 | new=0 | ETA 2.7m\n",
      "  37/1190 | solved=37 | new=0 | ETA 2.6m\n",
      "  38/1190 | solved=38 | new=0 | ETA 2.6m\n",
      "  39/1190 | solved=39 | new=0 | ETA 2.5m\n",
      "  40/1190 | solved=40 | new=0 | ETA 2.5m\n",
      "  41/1190 | solved=41 | new=0 | ETA 2.4m\n",
      "  42/1190 | solved=42 | new=0 | ETA 2.4m\n",
      "  43/1190 | solved=43 | new=0 | ETA 2.4m\n",
      "  44/1190 | solved=44 | new=0 | ETA 2.4m\n",
      "  45/1190 | solved=45 | new=0 | ETA 2.3m\n",
      "  46/1190 | solved=46 | new=0 | ETA 2.3m\n",
      "  47/1190 | solved=47 | new=0 | ETA 2.2m\n",
      "  48/1190 | solved=48 | new=0 | ETA 2.2m\n",
      "  49/1190 | solved=49 | new=0 | ETA 2.2m\n",
      "  50/1190 | solved=50 | new=0 | ETA 2.1m\n",
      "  51/1190 | solved=51 | new=0 | ETA 2.1m\n",
      "  52/1190 | solved=52 | new=0 | ETA 2.1m\n",
      "  53/1190 | solved=52 | new=0 | ETA 2.0m\n",
      "  54/1190 | solved=53 | new=0 | ETA 2.0m\n",
      "  55/1190 | solved=54 | new=0 | ETA 2.0m\n",
      "  56/1190 | solved=54 | new=0 | ETA 1.9m\n",
      "  57/1190 | solved=55 | new=0 | ETA 1.9m\n",
      "  58/1190 | solved=56 | new=0 | ETA 1.9m\n",
      "  59/1190 | solved=57 | new=0 | ETA 1.9m\n",
      "  60/1190 | solved=58 | new=0 | ETA 2.0m\n",
      "  61/1190 | solved=59 | new=0 | ETA 2.0m\n",
      "  62/1190 | solved=60 | new=0 | ETA 1.9m\n",
      "  63/1190 | solved=61 | new=0 | ETA 1.9m\n",
      "  64/1190 | solved=62 | new=0 | ETA 1.9m\n",
      "  65/1190 | solved=63 | new=0 | ETA 1.9m\n",
      "  66/1190 | solved=64 | new=0 | ETA 1.9m\n",
      "  67/1190 | solved=65 | new=0 | ETA 1.9m\n",
      "  68/1190 | solved=66 | new=0 | ETA 1.9m\n",
      "  69/1190 | solved=67 | new=0 | ETA 1.9m\n",
      "  70/1190 | solved=68 | new=0 | ETA 1.9m\n",
      "  71/1190 | solved=69 | new=0 | ETA 1.9m\n",
      "  72/1190 | solved=69 | new=0 | ETA 1.9m\n",
      "  73/1190 | solved=70 | new=0 | ETA 1.9m\n",
      "  74/1190 | solved=71 | new=0 | ETA 1.9m\n",
      "  75/1190 | solved=72 | new=0 | ETA 1.9m\n",
      "  76/1190 | solved=73 | new=0 | ETA 1.9m\n",
      "  77/1190 | solved=74 | new=0 | ETA 1.9m\n",
      "  78/1190 | solved=75 | new=0 | ETA 1.9m\n",
      "  79/1190 | solved=76 | new=0 | ETA 1.9m\n",
      "  80/1190 | solved=77 | new=0 | ETA 1.9m\n",
      "  81/1190 | solved=77 | new=0 | ETA 1.8m\n",
      "  82/1190 | solved=78 | new=0 | ETA 1.9m\n",
      "  83/1190 | solved=79 | new=0 | ETA 1.9m\n",
      "  84/1190 | solved=79 | new=0 | ETA 1.9m\n",
      "  85/1190 | solved=80 | new=0 | ETA 1.9m\n",
      "  86/1190 | solved=81 | new=0 | ETA 1.9m\n",
      "  87/1190 | solved=82 | new=0 | ETA 1.8m\n",
      "  88/1190 | solved=83 | new=0 | ETA 1.8m\n",
      "  89/1190 | solved=84 | new=0 | ETA 1.9m\n",
      "  90/1190 | solved=85 | new=0 | ETA 1.9m\n",
      "  91/1190 | solved=86 | new=0 | ETA 1.9m\n",
      "  92/1190 | solved=87 | new=0 | ETA 1.9m\n",
      "  93/1190 | solved=88 | new=0 | ETA 1.8m\n",
      "  94/1190 | solved=89 | new=0 | ETA 1.8m\n",
      "  95/1190 | solved=90 | new=0 | ETA 1.8m\n",
      "  96/1190 | solved=91 | new=0 | ETA 1.8m\n",
      "  97/1190 | solved=92 | new=0 | ETA 1.8m\n",
      "  98/1190 | solved=92 | new=0 | ETA 1.8m\n",
      "  99/1190 | solved=93 | new=0 | ETA 1.8m\n",
      "  100/1190 | solved=94 | new=0 | ETA 1.8m\n",
      "  101/1190 | solved=95 | new=0 | ETA 1.9m\n",
      "  102/1190 | solved=96 | new=0 | ETA 1.9m\n",
      "  103/1190 | solved=97 | new=0 | ETA 1.8m\n",
      "  104/1190 | solved=98 | new=0 | ETA 1.8m\n",
      "  105/1190 | solved=99 | new=0 | ETA 1.9m\n",
      "  106/1190 | solved=100 | new=0 | ETA 1.8m\n",
      "  107/1190 | solved=101 | new=0 | ETA 1.8m\n",
      "  108/1190 | solved=101 | new=0 | ETA 1.8m\n",
      "  109/1190 | solved=101 | new=0 | ETA 1.8m\n",
      "  110/1190 | solved=102 | new=0 | ETA 1.8m\n",
      "  111/1190 | solved=103 | new=0 | ETA 1.8m\n",
      "  112/1190 | solved=103 | new=0 | ETA 1.8m\n",
      "  113/1190 | solved=103 | new=0 | ETA 1.8m\n",
      "  114/1190 | solved=104 | new=0 | ETA 1.8m\n",
      "  115/1190 | solved=105 | new=0 | ETA 1.8m\n",
      "  116/1190 | solved=106 | new=0 | ETA 1.8m\n",
      "  117/1190 | solved=107 | new=0 | ETA 1.8m\n",
      "  118/1190 | solved=108 | new=0 | ETA 1.8m\n",
      "  119/1190 | solved=108 | new=0 | ETA 1.8m\n",
      "  120/1190 | solved=109 | new=0 | ETA 1.8m\n",
      "  121/1190 | solved=109 | new=0 | ETA 1.8m\n",
      "  122/1190 | solved=110 | new=0 | ETA 1.8m\n",
      "  123/1190 | solved=111 | new=0 | ETA 1.8m\n",
      "  124/1190 | solved=112 | new=0 | ETA 1.8m\n",
      "  125/1190 | solved=113 | new=0 | ETA 1.8m\n",
      "  126/1190 | solved=113 | new=0 | ETA 1.8m\n",
      "  127/1190 | solved=114 | new=0 | ETA 1.8m\n",
      "  128/1190 | solved=115 | new=0 | ETA 1.8m\n",
      "  129/1190 | solved=116 | new=0 | ETA 1.8m\n",
      "  130/1190 | solved=117 | new=0 | ETA 1.8m\n",
      "  131/1190 | solved=117 | new=0 | ETA 1.8m\n",
      "  132/1190 | solved=118 | new=0 | ETA 1.8m\n",
      "  133/1190 | solved=119 | new=0 | ETA 1.8m\n",
      "  134/1190 | solved=120 | new=0 | ETA 1.8m\n",
      "  135/1190 | solved=121 | new=0 | ETA 1.8m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/python3.12/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                 \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-505043351.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0malgo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malgos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_pres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_WORKERS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgreedy_solved_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0mall_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0malgo\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mall_solved_sets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0malgo\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'idx'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'solved'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipython-input-505043351.py\u001b[0m in \u001b[0;36mrun_parallel\u001b[0;34m(presentations, algorithm, config, num_workers, greedy_solved_set)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimap_unordered\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_worker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwork_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'solved'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.12/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    859\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m                     \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def run_parallel(presentations, algorithm, config, num_workers, greedy_solved_set):\n",
    "    \"\"\"Run search in parallel across all presentations.\"\"\"\n",
    "    n = len(presentations)\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"  {algorithm.upper()} | {config['max_nodes']:,} nodes | {num_workers} workers\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    work_items = [\n",
    "        (i, pres.tolist(), algorithm, config)\n",
    "        for i, pres in enumerate(presentations)\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    solved_count = 0\n",
    "    newly_solved_count = 0\n",
    "    t_start = time.time()\n",
    "    \n",
    "    with Pool(processes=num_workers) as pool:\n",
    "        for result in pool.imap_unordered(search_worker, work_items):\n",
    "            results.append(result)\n",
    "            if result['solved']:\n",
    "                solved_count += 1\n",
    "                if tuple(presentations[result['idx']]) not in greedy_solved_set:\n",
    "                    newly_solved_count += 1\n",
    "            \n",
    "            done = len(results)\n",
    "            # Changed from done % 50 == 0 to done % 1 == 0 to print EVERY result instantly\n",
    "            if done % 1 == 0 or done == n:\n",
    "                elapsed = time.time() - t_start\n",
    "                rate = elapsed / done\n",
    "                eta = rate * (n - done)\n",
    "                eta_s = f\"{eta/60:.1f}m\" if eta < 3600 else f\"{eta/3600:.1f}h\"\n",
    "                print(f\"  {done}/{n} | solved={solved_count} | \"\n",
    "                      f\"new={newly_solved_count} | ETA {eta_s}\")\n",
    "    \n",
    "    total_time = time.time() - t_start\n",
    "    results.sort(key=lambda r: r['idx'])\n",
    "    \n",
    "    solved_results = [r for r in results if r['solved']]\n",
    "    path_lengths = [r['path_length'] for r in solved_results]\n",
    "    \n",
    "    print(f\"\\n  RESULT: {len(solved_results)}/{n} solved \"\n",
    "          f\"({newly_solved_count} new beyond greedy) in {total_time/60:.1f}m\")\n",
    "    if path_lengths:\n",
    "        print(f\"  Avg path: {np.mean(path_lengths):.1f}, \"\n",
    "              f\"Max: {max(path_lengths)}, Min: {min(path_lengths)}\")\n",
    "    \n",
    "    # Show newly solved\n",
    "    newly = [r for r in solved_results \n",
    "             if tuple(presentations[r['idx']]) not in greedy_solved_set]\n",
    "    if newly:\n",
    "        print(f\"\\n  *** NEWLY SOLVED ({len(newly)} presentations) ***\")\n",
    "        for r in newly[:30]:\n",
    "            pres = presentations[r['idx']]\n",
    "            mrl = len(pres) // 2\n",
    "            tl = int(np.count_nonzero(pres[:mrl]) + np.count_nonzero(pres[mrl:]))\n",
    "            print(f\"    idx={r['idx']:>4d}, path_len={r['path_length']:>3d}, \"\n",
    "                  f\"word_len={tl}, nodes={r['nodes_explored']:>7d}\")\n",
    "        if len(newly) > 30:\n",
    "            print(f\"    ... and {len(newly)-30} more\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Build config\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "arch = ARCHITECTURE\n",
    "ckpt = f'value_search/checkpoints/best_{arch}.pt'\n",
    "stats = 'value_search/checkpoints/feature_stats.json'\n",
    "\n",
    "config = {\n",
    "    'device': device,\n",
    "    'architecture': arch,\n",
    "    'checkpoint': ckpt,\n",
    "    'feature_stats': stats,\n",
    "    'max_nodes': MAX_NODES,  # Default, used for V-guided and Beam\n",
    "    'beam_width': BEAM_WIDTH,\n",
    "    'c_explore': C_EXPLORE,\n",
    "    'cyclically_reduce': CYCLICALLY_REDUCE,\n",
    "}\n",
    "\n",
    "# Determine algorithms\n",
    "if ALGORITHM == 'all':\n",
    "    algos = ['v_guided', 'beam', 'mcts']\n",
    "else:\n",
    "    algos = [ALGORITHM]\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Algorithms to run: {algos}\")\n",
    "print(f\"Starting...\")\n",
    "\n",
    "all_results = {}\n",
    "all_solved_sets = {}\n",
    "\n",
    "for algo in algos:\n",
    "    # Give MCTS a smaller budget of 100,000 so it finishes reasonably fast!\n",
    "    algo_config = dict(config)\n",
    "    if algo == 'mcts':\n",
    "        algo_config['max_nodes'] = 100_000\n",
    "        \n",
    "    results = run_parallel(all_pres, algo, algo_config, NUM_WORKERS, greedy_solved_set)\n",
    "    all_results[algo] = results\n",
    "    all_solved_sets[algo] = set(r['idx'] for r in results if r['solved'])\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"  ALL DONE\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analysis-header",
   "metadata": {},
   "source": [
    "## 4. Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison table\n",
    "print(f\"{'Algorithm':<20} | {'Solved':>10} | {'New':>5} | {'Avg Path':>10} | {'Max Path':>10}\")\n",
    "print(f\"{'-'*20}-+-{'-'*10}-+-{'-'*5}-+-{'-'*10}-+-{'-'*10}\")\n",
    "\n",
    "for algo, results in all_results.items():\n",
    "    solved = [r for r in results if r['solved']]\n",
    "    newly = [r for r in solved if tuple(all_pres[r['idx']]) not in greedy_solved_set]\n",
    "    paths = [r['path_length'] for r in solved]\n",
    "    avg_p = f\"{np.mean(paths):.1f}\" if paths else \"\u2014\"\n",
    "    max_p = f\"{max(paths)}\" if paths else \"\u2014\"\n",
    "    print(f\"{algo:<20} | {f'{len(solved)}/1190':>10} | {len(newly):>5} | {avg_p:>10} | {max_p:>10}\")\n",
    "\n",
    "# Union\n",
    "if len(all_solved_sets) > 1:\n",
    "    union = set()\n",
    "    for s in all_solved_sets.values():\n",
    "        union |= s\n",
    "    union_new = sum(1 for idx in union if tuple(all_pres[idx]) not in greedy_solved_set)\n",
    "    print(f\"{'UNION':<20} | {f'{len(union)}/1190':>10} | {union_new:>5} |\")\n",
    "    \n",
    "    # Uniquely solved by each\n",
    "    print(f\"\\nUniquely solved:\")\n",
    "    for algo, s in all_solved_sets.items():\n",
    "        others = set().union(*(v for k, v in all_solved_sets.items() if k != algo))\n",
    "        unique = s - others\n",
    "        if unique:\n",
    "            print(f\"  {algo}: {len(unique)} unique\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all results\n",
    "timestamp = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "output_dir = f'experiments/results/{timestamp}_colab'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save config\n",
    "with open(f'{output_dir}/config.json', 'w') as f:\n",
    "    json.dump({\n",
    "        'algorithms': algos,\n",
    "        'max_nodes': MAX_NODES,\n",
    "        'workers': NUM_WORKERS,\n",
    "        'architecture': ARCHITECTURE,\n",
    "        'beam_width': BEAM_WIDTH,\n",
    "        'c_explore': C_EXPLORE,\n",
    "        'device': device,\n",
    "    }, f, indent=2)\n",
    "\n",
    "# Save per-algorithm results\n",
    "for algo, results in all_results.items():\n",
    "    with open(f'{output_dir}/{algo}_results.json', 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "\n",
    "# Save newly solved summary\n",
    "all_newly = {}\n",
    "for algo, results in all_results.items():\n",
    "    newly = [r for r in results if r['solved'] \n",
    "             and tuple(all_pres[r['idx']]) not in greedy_solved_set]\n",
    "    all_newly[algo] = [r['idx'] for r in newly]\n",
    "\n",
    "with open(f'{output_dir}/newly_solved.json', 'w') as f:\n",
    "    json.dump(all_newly, f, indent=2)\n",
    "\n",
    "print(f\"Results saved to: {output_dir}/\")\n",
    "print(f\"Files:\")\n",
    "for fname in sorted(os.listdir(output_dir)):\n",
    "    size = os.path.getsize(f'{output_dir}/{fname}')\n",
    "    print(f\"  {fname} ({size/1024:.0f} KB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verify-header",
   "metadata": {},
   "source": [
    "## 5. Verify Newly Solved Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verify-paths",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that all reported solutions are actually correct\n",
    "def verify_solution(pres, path):\n",
    "    \"\"\"Replay path and verify it reaches trivial.\"\"\"\n",
    "    state = np.array(pres, dtype=np.int8)\n",
    "    mrl = len(state) // 2\n",
    "    wl = [int(np.count_nonzero(state[:mrl])), int(np.count_nonzero(state[mrl:]))]\n",
    "    for action, expected_len in path:\n",
    "        state, wl = ACMove(action, state, mrl, wl, cyclical=False)\n",
    "    return is_presentation_trivial(state)\n",
    "\n",
    "print(\"Verifying all solutions...\")\n",
    "errors = 0\n",
    "verified = 0\n",
    "for algo, results in all_results.items():\n",
    "    for r in results:\n",
    "        if r['solved'] and 'path' in r:\n",
    "            path = [(a, l) for a, l in r['path']]\n",
    "            ok = verify_solution(all_pres[r['idx']], path)\n",
    "            if not ok:\n",
    "                print(f\"  ERROR: {algo} idx={r['idx']} path does NOT reach trivial!\")\n",
    "                errors += 1\n",
    "            verified += 1\n",
    "\n",
    "print(f\"Verified {verified} solutions, {errors} errors\")\n",
    "if errors == 0:\n",
    "    print(\"All solutions are verified correct! \u2713\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "download-header",
   "metadata": {},
   "source": [
    "## 6. Download Results (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "download",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip results for download\n",
    "import shutil\n",
    "zip_path = shutil.make_archive(f'/content/ac_solver_results_{timestamp}', 'zip', output_dir)\n",
    "print(f\"Results zipped to: {zip_path}\")\n",
    "\n",
    "# If running on Colab, offer download\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download(zip_path)\n",
    "except ImportError:\n",
    "    print(\"Not on Colab \u2014 download manually from the file browser.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}